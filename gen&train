# Установка необходимых библиотек
!pip install torch torchvision transformers diffusers accelerate safetensors pycocotools
​
import torch
from torch import nn
from torchvision import transforms
from diffusers import StableDiffusionPipeline
from huggingface_hub import login
import numpy as np
from PIL import Image
from datetime import datetime
import os
from pycocotools.coco import COCO
import requests
import zipfile
import shutil
​
# Функция для загрузки аннотаций COCO
def download_coco_annotations():
    coco_annotation_file = 'annotations/captions_train2017.json'
    
    if not os.path.exists(coco_annotation_file):
        url = 'http://images.cocodataset.org/annotations/annotations_trainval2017.zip'
        r = requests.get(url, stream=True)
        with open('annotations_trainval2017.zip', 'wb') as f:
            for chunk in r.iter_content(chunk_size=1024):
                if chunk:
                    f.write(chunk)
        # Извлечение нужного файла из архива
        with zipfile.ZipFile('annotations_trainval2017.zip', 'r') as zip_ref:
            zip_ref.extract('annotations/captions_train2017.json', '.')
    
    return coco_annotation_file
​
# Функция для генерации изображения и получения шума
def generate_image_and_noise(prompt, pipe):
    noise = torch.randn((1, pipe.unet.config.in_channels, pipe.unet.config.sample_size, pipe.unet.config.sample_size), device="cuda", dtype=torch.float16)
    with torch.no_grad():
        image = pipe(prompt=prompt, latents=noise).images[0]
    return noise, image
​
# Главная функция
def main():
    # Установите токен в переменную среды
    os.environ["HUGGINGFACE_TOKEN"] = "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"  # Замените на ваш токен
​
    # Загрузка модели
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,
        use_safetensors=True,
        use_auth_token=os.environ["HUGGINGFACE_TOKEN"]
    )
    pipe.to("cuda")
​
    # Загрузка аннотаций COCO
    coco_annotation_file = download_coco_annotations()
    coco = COCO(coco_annotation_file)
    anns = coco.loadAnns(coco.getAnnIds())
    captions = [ann['caption'] for ann in anns]
​
    # Ограничим количество запросов до первых 100
    captions = captions[:100]
    print(f"Загружено {len(captions)} текстовых запросов из COCO.")
​
    # Создайте папки для сохранения изображений и шума, если они не существуют
    output_dir = "generated_images"
    noise_dir = "generated_noise"
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(noise_dir, exist_ok=True)
​
    # Определение модели студента (например, U-Net)
    student_model = nn.Sequential(
        nn.Conv2d(4, 64, kernel_size=3, padding=1),
        nn.ReLU(),
        nn.Conv2d(64, 3, kernel_size=3, padding=1)
    ).cuda().half()
​
    optimizer = torch.optim.Adam(student_model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()
​
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Resize((512, 512)),
        transforms.Normalize([0.5], [0.5])
    ])
​
    for i, prompt in enumerate(captions):
        print(f"Генерация и обучение для текста: {prompt}")
        
        # Генерация изображения и шума
        noise, teacher_image = generate_image_and_noise(prompt, pipe)
        
        # Подготовка данных для обучения студента
        teacher_image = transform(teacher_image).unsqueeze(0).cuda().half()
        noises = noise.cuda().half()
        noises_resized = torch.nn.functional.interpolate(noises, size=(512, 512))
​
        timesteps = torch.tensor([pipe.scheduler.timesteps[-1]], dtype=torch.long, device="cuda")
        
        # Получение эмбеддингов текстов
        tokenizer = pipe.tokenizer
        input_ids = tokenizer(prompt, return_tensors="pt", padding="max_length", truncation=True, max_length=77).input_ids.cuda()
        encoder_hidden_states = pipe.text_encoder(input_ids)[0]
​
        # Обучение модели студента
        optimizer.zero_grad()
        outputs = student_model(noises_resized)
        loss = criterion(outputs, teacher_image)
        loss.backward()
        optimizer.step()
​
        # Сохранение изображения и шума
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S%f")
        image_path = os.path.join(output_dir, f"generated_image_{timestamp}.png")
        noise_path = os.path.join(noise_dir, f"generated_noise_{timestamp}.npy")
        teacher_image.squeeze(0).cpu().numpy().tofile(image_path)
        np.save(noise_path, noises.cpu().numpy())
​
        print(f"Изображение сохранено по пути: {image_path}")
        print(f"Шум сохранен по пути: {noise_path}")
​
if __name__ == '__main__':
    main()
​
